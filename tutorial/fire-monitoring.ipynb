{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fire monitoring tutorial\n",
    "\n",
    "This tutorial provides an overview of our [open source pipeline](https://github.com/carbonplan/forest-offsets-fires) for generating a cloud-optimized GeoParquet dataset for active and recent fires, along with vector tiles for performant visualization."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages\n",
    "\n",
    "We've packaged most of the utilities needed for the data pipeline in the `carbonplan_forest_offsets_fires` Python library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from carbonplan_forest_offsets_fires.firms import (\n",
    "    read_firms_nrt,\n",
    "    filter_df,\n",
    "    mask_df,\n",
    "    make_tile_tempdir,\n",
    "    write_firms_json,\n",
    "    build_tippecanoe_cmd,\n",
    "    build_pbf_cmd,\n",
    "    upload_tiles,\n",
    ")\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "from tempfile import TemporaryDirectory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define parameters\n",
    "\n",
    "We define these parameters for creating a cloud-optimized dataset for the continental United States and Alaska."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_range = 3\n",
    "params = {'min_lat': 24, 'max_lat': 72, 'min_lon': -180, 'max_lon': -66, 'day_range': day_range}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and transform data from the FIRMS API\n",
    "\n",
    "In this section, we use the utilities in CarbonPlan's fire monitoring Python package to query the FIRMS API, subset the data, filter out low confidence data, and transform into a GeoDataFrame.\n",
    "\n",
    "For this to work, you need to have a valid API token stored in the environment variable ``FIRMS_MAP_KEY``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snpp = read_firms_nrt(\n",
    "    **params,\n",
    "    source=\"VIIRS_SNPP_NRT\",\n",
    ").pipe(filter_df)\n",
    "df_noaa20 = read_firms_nrt(\n",
    "    **params,\n",
    "    source=\"VIIRS_NOAA20_NRT\",\n",
    ").pipe(filter_df)\n",
    "df_modis = read_firms_nrt(\n",
    "    **params,\n",
    "    source=\"MODIS_NRT\",\n",
    ").pipe(filter_df)\n",
    "df = pd.concat([df_snpp, df_noaa20, df_modis])\n",
    "gdf = mask_df(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write output to GeoParquet\n",
    "In this section, we'll write the output to GeoParquet. We'll write to a temporary directory for this tutorial. For the production pipeline, we write the data to cloud object storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = TemporaryDirectory()\n",
    "gdf.to_parquet(f'{td.name}/current-firms-pixels.parquet')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create tiles\n",
    "Now that we have the data in a cloud-optimized format, we'll also create vector tiles for performant viewing in the browser. We'll use the [tippecanoe](https://github.com/mapbox/tippecanoe) library to build the tiles. The output from these are written to temporary directories. In the production workflow, we upload the Protocol Buffer files derived from vector tiles to AWS S3 for rendering in the [monitoring forest offsets and fires web tool](https://carbonplan.org/research/forest-offsets-fires)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEM = 'current-firms-pixels'\n",
    "# Create temporary GeoJSON that can be read by tippecanoe\n",
    "tempdir = make_tile_tempdir()\n",
    "json_fp = write_firms_json(data=gdf, tempdir=tempdir)\n",
    "# Use tippecanoe to generate vector tiles\n",
    "tippecanoe_cmd = build_tippecanoe_cmd(input_fn=json_fp, tempdir=tempdir, stem=STEM)\n",
    "subprocess.run(tippecanoe_cmd)\n",
    "# Use mb-util to generate pbf files from vector tiles\n",
    "pbf_cmd = build_pbf_cmd(tempdir=tempdir, stem=STEM)\n",
    "subprocess.run(pbf_cmd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fire-monitoring-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
